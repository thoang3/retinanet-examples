# 10-21-2019

- Test 1GPU with default learning rate  (0.01) with resnet50 => loss diverge at 11000 iteration!
- For resnet50, cannot have batch size > 2.

# 10-22-2019

- Test 1GPU with lr = 0.001 with resnet18  => diverge after 8000
- Try with lr = 0.0001, batch size =4 with resnet18 => seem to work ok, at 14000 now
- Test again with lr = 0.001 with resnet18, but batch size = 4 => converge. Result after 8000 iterations:
[ 7985/90000] focal loss: 0.651, box loss: 0.271, 0.394s/4-batch (fw: 0.163s, bw: 0.231s), 10.1 im/s, lr: 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.01435
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.03335

[15872/90000] focal loss: 0.564, box loss: 0.244, 0.389s/4-batch (fw: 0.161s, bw: 0.228s), 10.3 im/s, lr: 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.03798
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.07720

- For resnet34, lr = 0.001 with batch 4 seem to work (at 5200 iterations now). There's a chance of getting CUDA out of memory though. 

[  7990/360000] focal loss: 0.666, box loss: 0.256, 0.390s/3-batch (fw: 0.169s, bw: 0.220s), 7.7 im/s, lr: 0.001
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.01303
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.02949
 

- It seems like passing new learning rate when resuming training doesn't work. The model still loads previous configuration. Update: Fixed with the new code!! 

# 10-23-2019

- Test resnet50 with 1 GPU
- Test resnet50, lr = 0.01, warmup = 5000 => diverge at 2000 iterations
- Test resnet50, lr = 0.005, warmup = 5000 => diverge at 5700 iterations, however, can run to 8000 iterations when resume. 

[ 23957/360000] focal loss: 0.666, box loss: 0.230, 0.301s/2-batch (fw: 0.113s, bw: 0.187s), 6.6 im/s, lr: 0.005
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.01305
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.02578

=> at 360000: mAP = 0.24680 !!!!


 # 10-24-2019

- Test resnet34 with 4GPUs, lr = 0.01, rest default => mAP = 0.31481, which is ~3% lower. 
- Need to train with more iterations. 

